{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a095f6fe",
   "metadata": {},
   "source": [
    "## PINN framework for laminated plates\n",
    "This framework predicts the bending behavior of laminated plates based on Classical Laminate Plate Theory (CLPT). Taking a simply supported (0/90) plate under uniform distributed load (UDL) as an example, other cases can be predicted by modifying the parameters in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0bb3d",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c48f62",
   "metadata": {},
   "source": [
    "## Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28656acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FNN\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, n_input, n_output, n_layer, n_nodes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        \n",
    "        self.Input = nn.Linear(n_input, n_nodes)\n",
    "        nn.init.xavier_uniform_(self.Input.weight)\n",
    "        nn.init.normal_(self.Input.bias)\n",
    "\n",
    "        self.Output = nn.Linear(n_nodes, n_output)\n",
    "        nn.init.xavier_uniform_(self.Output.weight)\n",
    "        nn.init.normal_(self.Output.bias)\n",
    "        \n",
    "        self.Hidden = nn.ModuleList()\n",
    "        for i in range(n_layer):\n",
    "            self.Hidden.append(nn.Linear(n_nodes, n_nodes))\n",
    "        for layer in self.Hidden:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            nn.init.normal_(layer.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = torch.tanh(self.Input(x))\n",
    "        for layer in self.Hidden:\n",
    "            y = torch.tanh(layer(y))\n",
    "        y = self.Output(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6188fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto differential\n",
    "def auto_grad(u, x, order=1):\n",
    "    if order == 1:\n",
    "        return torch.autograd.grad(u, x, torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
    "    return auto_grad(auto_grad(u, x), x, order - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ea098",
   "metadata": {},
   "source": [
    "## CLPT stiffness matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef783b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the transformed matrix\n",
    "def transformed_matrix(phi,opt):\n",
    "\n",
    "    anpha=np.deg2rad(phi)\n",
    "    m=math.cos(anpha)\n",
    "    n=math.sin(anpha)\n",
    "    if abs(m) < 2.2204e-10:\n",
    "        m=0\n",
    "    if abs(n) < 2.2204e-10:\n",
    "        n=0    \n",
    "  \n",
    "    if opt==1:\n",
    "        T = np.array([[m**2, n**2, 2*m*n ],\n",
    "                   [n**2, m**2, -2*m*n ],\n",
    "                   [-m*n, m*n, m**2-n**2]])\n",
    "    else:\n",
    "        T = np.array([[m**2, n**2, m*n ],\n",
    "                   [n**2, m**2, -m*n ],\n",
    "                   [-2*m*n, 2*m*n, m**2-n**2]])\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f17e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define geometric parameters\n",
    "a = 5 \n",
    "b = 5 \n",
    "h = 1 # Total thickness of the laminate\n",
    "n_layer = 2 # Number of layers\n",
    "t = h/n_layer # Thickness of each layer\n",
    "phi = [0,90] # lay-ups\n",
    "q0 = 1e-3 \n",
    "# SDL: q0 * torch.sin(3.1415/2*(x[:,0]+1)).view(-1,1)* torch.sin(3.1415/2*(x[:,1]+1)).view(-1,1)\n",
    "\n",
    "# Define material parameters\n",
    "E1 = 25\n",
    "E2 = E1/25\n",
    "G12 = 0.5*E2\n",
    "mu12 = 0.25\n",
    "mu21 = mu12*E2/E1\n",
    "\n",
    "# Stiffness matrix for an orthotropic material\n",
    "Q11 = E1/(1 - mu12*mu21)\n",
    "Q12 = mu12*E2/(1 - mu12*mu21)\n",
    "Q22 = E2/(1 - mu12*mu21)\n",
    "Q66 = G12    \n",
    "Q = np.array([[Q11, Q12 , 0],[Q12 , Q22, 0],[0, 0, Q66]])\n",
    "\n",
    "# Transform stiffness matrix for each layer\n",
    "Q_bar =[]\n",
    "for i in range(n_layer):\n",
    "        T2=transformed_matrix(phi[i],2)\n",
    "        Q2=T2.T@Q@T2\n",
    "        Q_bar.append(Q2)\n",
    "        \n",
    "# Calculate z-coordinates for each layer       \n",
    "z1 = []\n",
    "for i in range(n_layer):\n",
    "    zi=((i)-n_layer/2)*t\n",
    "    z1.append(zi)\n",
    "z1 = np.array(z1)\n",
    "\n",
    "z2 = []\n",
    "for i in range(n_layer):\n",
    "    zi=((i+1)-n_layer/2)*t\n",
    "    z2.append(zi)\n",
    "z2 = np.array(z2)\n",
    "\n",
    "# Compute A, B, D matrices\n",
    "A = np.zeros(shape=(3,3))\n",
    "B = np.zeros(shape=(3,3))\n",
    "D = np.zeros(shape=(3,3))\n",
    "for i in range(n_layer):\n",
    "    A = A + Q_bar[i] * (z2[i] - z1[i])\n",
    "    B = B + Q_bar[i] * (z2[i]**2 - z1[i]**2)/2\n",
    "    D = D + Q_bar[i] * (z2[i]**3 - z1[i]**3)/3\n",
    "print(\"A matrix:\\n\", A)\n",
    "print(\"B matrix:\\n\", B)\n",
    "print(\"D matrix:\\n\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bdb6ad",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75786d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling point\n",
    "def train_data(Nx, Ny, Nf):\n",
    "    \n",
    "    xu = np.linspace(-1, 1, Nx).reshape([Nx, 1])\n",
    "    yu = np.linspace(-1, 1, Ny).reshape([Ny, 1]) \n",
    "    X, Y = np.meshgrid(xu, yu)\n",
    "    Xf1 = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    Xf1 = torch.tensor(Xf1, dtype=torch.float32, requires_grad=True)\n",
    "    Xf1 = torch.cat([Xf1,Xb],axis = 0)\n",
    "\n",
    "    Xf2 = np.random.rand(Nf,2)*2-1\n",
    "    Xf2 = torch.tensor(Xf2, dtype=torch.float32, requires_grad=True)\n",
    "    Xf2 = torch.cat([Xf2,Xb],axis = 0)\n",
    "    \n",
    "    return Xb, Xf1, Xf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d7ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "Nxb= 100\n",
    "Nyb = 100\n",
    "Nf1 = 10000\n",
    "\n",
    "Xb, Xf1, Xf2 = train_data(Nxb, Nyb, Nf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6f582",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d56f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Energy_loss(x, Net_w, func_w, Net_u, func_u, Net_v, func_v):\n",
    "    \n",
    "    q = q0\n",
    "    # SDL: q = q0 * torch.sin(3.1415/2*(x[:,0]+1)).view(-1,1)* torch.sin(3.1415/2*(x[:,1]+1)).view(-1,1)    \n",
    "    u = Net_u(x)*(func_u(x).view(-1,1))\n",
    "    du_x = auto_grad(u, x, 1)[:,0].view(-1,1)\n",
    "    du_y = auto_grad(u, x, 1)[:,1].view(-1,1)\n",
    "    v = Net_v(x)*(func_v(x).view(-1,1))\n",
    "    dv_x = auto_grad(v, x, 1)[:,0].view(-1,1)\n",
    "    dv_y = auto_grad(v, x, 1)[:,1].view(-1,1)\n",
    "    w = Net_w(x)*(func_w(x).view(-1,1))\n",
    "    dw_x = auto_grad(w, x, 1)[:,0].view(-1,1)\n",
    "    dw_y = auto_grad(w, x, 1)[:,1].view(-1,1)\n",
    "    dw_xx = auto_grad(dw_x, x, 1)[:,0].view(-1,1)\n",
    "    dw_yy = auto_grad(dw_y, x, 1)[:,1].view(-1,1)\n",
    "    dw_xy = auto_grad(dw_x, x, 1)[:,1].view(-1,1)\n",
    "    \n",
    "    w = w*h\n",
    "    dw_x, dw_y, du_y, dv_x = dw_x*h/a, dw_y*h/b, du_y*a/b, dv_x*b/a\n",
    "    dw_xx, dw_yy, dw_xy = dw_xx*h/a**2, dw_yy*h/b**2, dw_xy*h/a/b\n",
    "    \n",
    "    eps_xx = du_x + 0.5*dw_x**2\n",
    "    eps_yy = dv_y + 0.5*dw_y**2\n",
    "    eps_xy = 0.5*(du_y + dv_x) + 0.5*dw_y*dw_x   \n",
    "        \n",
    "    k_xx = -dw_xx\n",
    "    k_yy = -dw_yy\n",
    "    k_xy = -dw_xy\n",
    "    \n",
    "    N_xx = A[0,0]*eps_xx + A[0,1]*eps_yy + A[0,2]*2*eps_xy  + B[0,0]*k_xx + B[0,1]*k_yy + B[0,2]*2*k_xy \n",
    "    N_yy = A[1,0]*eps_xx + A[1,1]*eps_yy + A[1,2]*2*eps_xy  + B[1,0]*k_xx + B[1,1]*k_yy + B[1,2]*2*k_xy \n",
    "    N_xy = A[2,0]*eps_xx + A[2,1]*eps_yy + A[2,2]*2*eps_xy  + B[2,0]*k_xx + B[2,1]*k_yy + B[2,2]*2*k_xy \n",
    "   \n",
    "    M_xx = B[0,0]*eps_xx + B[0,1]*eps_yy + B[0,2]*2*eps_xy  + D[0,0]*k_xx + D[0,1]*k_yy + D[0,2]*2*k_xy\n",
    "    M_yy = B[1,0]*eps_xx + B[1,1]*eps_yy + B[1,2]*2*eps_xy  + D[1,0]*k_xx + D[1,1]*k_yy + D[1,2]*2*k_xy\n",
    "    M_xy = B[2,0]*eps_xx + B[2,1]*eps_yy + B[2,2]*2*eps_xy  + D[2,0]*k_xx + D[2,1]*k_yy + D[2,2]*2*k_xy\n",
    "    \n",
    "    U_m = 0.5*(eps_xx*N_xx + eps_yy*N_yy + 2*eps_xy*N_xy)\n",
    "    U_b = 0.5*(k_xx*M_xx + k_yy*M_yy + 2*k_xy*M_xy)\n",
    "    U_e = q*w \n",
    "    \n",
    "    return torch.mean(U_m), torch.mean(U_b), torch.mean(U_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c72b90",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent nn for three directions\n",
    "Net_w = NeuralNetwork(2,1,5,5)\n",
    "Net_u = NeuralNetwork(2,1,5,5)\n",
    "Net_v = NeuralNetwork(2,1,5,5)\n",
    "\n",
    "# Hard constrains for essential BCs (SSSS)\n",
    "func_w = lambda x: ((x[:,0]+1)*(x[:,0]-1)*(x[:,1]+1)*(x[:,1]-1))\n",
    "func_u = lambda x: (x[:,1]+1)*(x[:,1]-1)\n",
    "func_v = lambda x: (x[:,0]+1)*(x[:,0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4945b1ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Construct neural network\n",
    "# optimizer\n",
    "nepoches = 10000\n",
    "initial_epochs = 100\n",
    "learning_rate = 1e-3\n",
    "training_loss_hist = []\n",
    "W_pred_hist = []\n",
    "optimizer = torch.optim.Adam(list(Net_w.parameters()) + list(Net_u.parameters()) + list(Net_v.parameters()), \n",
    "                             lr= learning_rate)\n",
    "for epoch in range(nepoches):\n",
    "        \n",
    "    if epoch < initial_epochs:\n",
    "        _, Xf1, _ = train_data(Nxb, Nyb, Nf1)\n",
    "        Xf = Xf1\n",
    "    else:\n",
    "        _, _, Xf2 = train_data(Nxb, Nyb, Nf1)\n",
    "        Xf = Xf2\n",
    "\n",
    "    U_m, U_b, U_e = Energy_loss(Xf, Net_w, func_w, Net_u, func_u, Net_v, func_v)\n",
    "    \n",
    "    loss = U_m + U_b - U_e\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    training_loss_hist.append(loss.item())   \n",
    "        \n",
    "    if (epoch+1) % 1 ==0: \n",
    "        with torch.no_grad():\n",
    "            W_pred = Net_w(Xf1)*func_w(Xf1).view(-1,1)*100*(h)**3*E2/q0/(2*a)**4\n",
    "            W_pred_hist.append(max(W_pred))\n",
    "            \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'epoch:{epoch+1}, Total:{loss:.4e}, Membrane:{U_m:.4e}, Bending:{U_b:.4e}, External:{U_e:.4e}, W:{max(W_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c608e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = Net_w(Xf1)*(func_w(Xf1).view(-1,1))\n",
    "W_pred = W.detach().numpy().reshape(-1,1)*h\n",
    "W_bar = W_pred*100*(h)**3*E2/q0/(2*a)**4\n",
    "X = Xf1[:,0].detach().numpy().reshape(-1,1)*a\n",
    "Y = Xf1[:,1].detach().numpy().reshape(-1,1)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "fig, ax = plt.subplots(figsize=(5.8, 4.8)) \n",
    "surf = ax.scatter(X, Y, c=W_bar,cmap=cm.jet)\n",
    "cb = fig.colorbar(surf, ax=ax, orientation='vertical')\n",
    "cb.ax.tick_params(labelsize=16)\n",
    "vmin = W_bar.min().item()\n",
    "vmax = W_bar.max().item()\n",
    "num_ticks = 6\n",
    "ticks = np.linspace(vmin, vmax, num_ticks)\n",
    "cb.set_ticks(ticks)\n",
    "\n",
    "ax.axis('equal')  \n",
    "ax.set_xlabel('X Position (mm)', fontsize=18)\n",
    "ax.set_ylabel('Y Position (mm)', fontsize=18)\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "ax.set_title(r'$\\overline{w}_{0}$ on mid-plane', fontsize=18)\n",
    "ax.set_xlim([X.min(), X.max()])\n",
    "ax.set_ylim([Y.max(), Y.min()])\n",
    "xticks = [-5, -2.5, 0, 2.5, 5] \n",
    "xlabels = ['-a', '-a/2', '0', 'a/2', 'a']\n",
    "yticks = [-5, -2.5, 0, 2.5, 5]\n",
    "ylabels = ['-b', '-b/2', '0', 'b/2', 'b'] \n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xlabels, fontsize=16)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels, fontsize=16)\n",
    "ax.set_xlabel('X Position', fontsize=18)\n",
    "ax.set_ylabel('Y Position', fontsize=18)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01525215",
   "metadata": {},
   "source": [
    "## FEM comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff87871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEM_data = pd.read_csv('FEM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = FEM_data.iloc[:,0:2].to_numpy()\n",
    "coord_nor = coord/500\n",
    "X = coord_nor[:, 0]\n",
    "Y = coord_nor[:, 1]\n",
    "sigma = FEM_data.iloc[:,3:6].to_numpy()\n",
    "sigmaxx = sigma[:, 0]\n",
    "sigmayy = sigma[:, 1]\n",
    "sigmaxy = sigma[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6)) \n",
    "\n",
    "surf1 = axes[0].scatter(X, Y, c=sigmaxx, cmap=cm.jet)\n",
    "cb1 = fig.colorbar(surf1, ax=axes[0], orientation='vertical', shrink=0.8)\n",
    "cb1.ax.tick_params(labelsize=16)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[0].set_ylabel('Y Position (mm)', fontsize=18)\n",
    "axes[0].set_title(r'$\\overline{\\sigma}_{xx}$ Distribution', fontsize=18)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[0].set_xlim([X.min(), X.max()])\n",
    "axes[0].set_ylim([Y.max(), Y.min()])\n",
    "axes[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "surf2 = axes[1].scatter(X, Y, c=sigmayy, vmin=0, cmap=cm.jet)\n",
    "cb2 = fig.colorbar(surf2, ax=axes[1], orientation='vertical', shrink=0.8)\n",
    "cb2.ax.tick_params(labelsize=16)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[1].set_title(r'$\\overline{\\sigma}_{yy}$ Distribution', fontsize=18)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[1].set_xlim([X.min(), X.max()])\n",
    "axes[1].set_ylim([Y.max(), Y.min()])\n",
    "axes[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "surf3 = axes[2].scatter(X, Y, c=-sigmaxy, cmap=cm.jet)\n",
    "cb3 = fig.colorbar(surf3, ax=axes[2], orientation='vertical', shrink=0.8)\n",
    "cb3.ax.tick_params(labelsize=16)\n",
    "axes[2].axis('equal')\n",
    "axes[2].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[2].set_title(r'$\\overline{\\sigma}_{xy}$ Distribution', fontsize=18)\n",
    "axes[2].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[2].set_xlim([X.min(), X.max()])\n",
    "axes[2].set_ylim([Y.max(), Y.min()])\n",
    "axes[2].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adfbcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_nor = torch.tensor(coord_nor, dtype=torch.float32, requires_grad=True)\n",
    "u = Net_u(coord_nor)*(func_u(coord_nor).view(-1,1))\n",
    "du_x = auto_grad(u, coord_nor, 1)[:,0].view(-1,1)\n",
    "du_y = auto_grad(u, coord_nor, 1)[:,1].view(-1,1)\n",
    "v = Net_v(coord_nor)*(func_v(coord_nor).view(-1,1))\n",
    "dv_x = auto_grad(v, coord_nor, 1)[:,0].view(-1,1)\n",
    "dv_y = auto_grad(v, coord_nor, 1)[:,1].view(-1,1)\n",
    "w = Net_w(coord_nor)*(func_w(coord_nor).view(-1,1))\n",
    "dw_x = auto_grad(w, coord_nor, 1)[:,0].view(-1,1)\n",
    "dw_y = auto_grad(w, coord_nor, 1)[:,1].view(-1,1)\n",
    "dw_xx = auto_grad(dw_x, coord_nor, 1)[:,0].view(-1,1)\n",
    "dw_yy = auto_grad(dw_y, coord_nor, 1)[:,1].view(-1,1)\n",
    "dw_xy = auto_grad(dw_x, coord_nor, 1)[:,1].view(-1,1)\n",
    "\n",
    "w = w*h\n",
    "dw_x, dw_y, du_y, dv_x = dw_x*h/a, dw_y*h/b, du_y*a/b, dv_x*b/a\n",
    "dw_xx, dw_yy, dw_xy = dw_xx*h/a**2, dw_yy*h/b**2, dw_xy*h/a/b\n",
    "\n",
    "eps_xx = du_x + 0.5*dw_x**2\n",
    "eps_yy = dv_y + 0.5*dw_y**2\n",
    "eps_xy = 0.5*(du_y + dv_x) + 0.5*dw_y*dw_x   \n",
    "\n",
    "k_xx = -dw_xx\n",
    "k_yy = -dw_yy\n",
    "k_xy = -dw_xy\n",
    "\n",
    "N_xx = A[0,0]*eps_xx + A[0,1]*eps_yy + A[0,2]*2*eps_xy  + B[0,0]*k_xx + B[0,1]*k_yy + B[0,2]*2*k_xy \n",
    "N_yy = A[1,0]*eps_xx + A[1,1]*eps_yy + A[1,2]*2*eps_xy  + B[1,0]*k_xx + B[1,1]*k_yy + B[1,2]*2*k_xy \n",
    "N_xy = A[2,0]*eps_xx + A[2,1]*eps_yy + A[2,2]*2*eps_xy  + B[2,0]*k_xx + B[2,1]*k_yy + B[2,2]*2*k_xy \n",
    "\n",
    "M_xx = B[0,0]*eps_xx + B[0,1]*eps_yy + B[0,2]*2*eps_xy  + D[0,0]*k_xx + D[0,1]*k_yy + D[0,2]*2*k_xy\n",
    "M_yy = B[1,0]*eps_xx + B[1,1]*eps_yy + B[1,2]*2*eps_xy  + D[1,0]*k_xx + D[1,1]*k_yy + D[1,2]*2*k_xy\n",
    "M_xy = B[2,0]*eps_xx + B[2,1]*eps_yy + B[2,2]*2*eps_xy  + D[2,0]*k_xx + D[2,1]*k_yy + D[2,2]*2*k_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINN_sigmaxx = Q_bar[1][0,0]*eps_xx + Q_bar[1][0,1]*eps_yy + Q_bar[1][0,2]*2*eps_xy + 0.5* ( Q_bar[1][0,0]*k_xx +  Q_bar[1][0,1]*k_yy +  Q_bar[1][0,2]*2*k_xy )\n",
    "PINN_sigmayy = Q_bar[1][1,0]*eps_xx + Q_bar[1][1,1]*eps_yy + Q_bar[1][1,2]*2*eps_xy + 0.5* ( Q_bar[1][1,0]*k_xx +  Q_bar[1][1,1]*k_yy +  Q_bar[1][1,2]*2*k_xy )\n",
    "PINN_sigmaxy = Q_bar[1][2,0]*eps_xx + Q_bar[1][2,1]*eps_yy + Q_bar[1][2,2]*2*eps_xy + 0.5* ( Q_bar[1][2,0]*k_xx +  Q_bar[1][2,1]*k_yy +  Q_bar[1][2,2]*2*k_xy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23668e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINN_sigmaxx = PINN_sigmaxx.detach().numpy()*(h)**2/q0/(2*a)**2\n",
    "PINN_sigmayy = PINN_sigmayy.detach().numpy()*(h)**2/q0/(2*a)**2\n",
    "PINN_sigmaxy = PINN_sigmaxy.detach().numpy()*(h)**2/q0/(2*a)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.sum((PINN_sigmaxx - sigmaxx)**2)  \n",
    "denominator = np.sum((sigmaxx - np.mean(sigmaxx))**2) \n",
    "sigmaxx_r2 = 1 - (numerator / denominator)\n",
    "print(\"R-squared (sigmaxx):\", sigmaxx_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.sum((PINN_sigmayy - sigmayy)**2)  \n",
    "denominator = np.sum((sigmayy - np.mean(sigmayy))**2) \n",
    "sigmayy_r2 = 1 - (numerator / denominator)\n",
    "print(\"R-squared (sigmayy):\", sigmayy_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc68cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = np.sum((PINN_sigmaxy - sigmaxy)**2)  \n",
    "denominator = np.sum((sigmaxy - np.mean(sigmaxy))**2) \n",
    "sigmaxy_r2 = 1 - (numerator / denominator)\n",
    "print(\"R-squared (sigmaxy):\", sigmaxy_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd86ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6)) \n",
    "xticks = [-1, -0.5, 0, 0.5, 1] \n",
    "xlabels = ['-a', '-a/2', '0', 'a/2', 'a']\n",
    "yticks = [-1, -0.5, 0, 0.5, 1]\n",
    "ylabels = ['-b', '-b/2', '0', 'b/2', 'b'] \n",
    "surf1 = axes[0].scatter(X, Y, c=PINN_sigmaxx, cmap=cm.jet)\n",
    "cb1 = fig.colorbar(surf1, ax=axes[0], orientation='vertical', shrink=0.8)\n",
    "cb1.ax.tick_params(labelsize=16)\n",
    "axes[0].axis('equal')\n",
    "axes[0].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[0].set_ylabel('Y Position (mm)', fontsize=18)\n",
    "axes[0].set_title(f'$\\overline{{\\sigma}}_{{xx}}$ Distribution ($R^2$: {sigmaxx_r2})', fontsize=18)\n",
    "axes[0].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[0].set_xlim([X.min(), X.max()])\n",
    "axes[0].set_ylim([Y.max(), Y.min()])\n",
    "axes[0].set_xticks(xticks)\n",
    "axes[0].set_xticklabels(xlabels, fontsize=16)\n",
    "axes[0].set_yticks(yticks)\n",
    "axes[0].set_yticklabels(ylabels, fontsize=16)\n",
    "axes[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "surf2 = axes[1].scatter(X, Y, c=PINN_sigmayy, vmin=0, cmap=cm.jet)\n",
    "cb2 = fig.colorbar(surf2, ax=axes[1], orientation='vertical', shrink=0.8)\n",
    "cb2.ax.tick_params(labelsize=16)\n",
    "axes[1].axis('equal')\n",
    "axes[1].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[1].set_title(f'$\\overline{{\\sigma}}_{{yy}}$ Distribution ($R^2$: {sigmayy_r2})', fontsize=18)\n",
    "axes[1].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[1].set_xlim([X.min(), X.max()])\n",
    "axes[1].set_ylim([Y.max(), Y.min()])\n",
    "axes[1].set_xticks(xticks)\n",
    "axes[1].set_xticklabels(xlabels, fontsize=16)\n",
    "axes[1].set_yticks(yticks)\n",
    "axes[1].set_yticklabels(ylabels, fontsize=16)\n",
    "axes[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "surf3 = axes[2].scatter(X, Y, c=PINN_sigmaxy, cmap=cm.jet)\n",
    "cb3 = fig.colorbar(surf3, ax=axes[2], orientation='vertical', shrink=0.8)\n",
    "cb3.ax.tick_params(labelsize=16)\n",
    "axes[2].axis('equal')\n",
    "axes[2].set_xlabel('X Position (mm)', fontsize=18)\n",
    "axes[2].set_title(f'$\\overline{{\\sigma}}_{{xy}}$ Distribution ($R^2$: {sigmaxy_r2})', fontsize=18)\n",
    "axes[2].tick_params(axis='both', which='major', labelsize=16)\n",
    "axes[2].set_xlim([X.min(), X.max()])\n",
    "axes[2].set_ylim([Y.max(), Y.min()])\n",
    "axes[2].set_xticks(xticks)\n",
    "axes[2].set_xticklabels(xlabels, fontsize=16)\n",
    "axes[2].set_yticks(yticks)\n",
    "axes[2].set_yticklabels(ylabels, fontsize=16)\n",
    "axes[2].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a71dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
